{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c20d5284-43a5-4c57-9006-828f0883a2b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import sklearn.pipeline \n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import optuna\n",
    "\n",
    "sys.path.append(\"/home/icb/sergey.vilov/workspace/MLM/mpra/utils/\") \n",
    "\n",
    "from mlp import *\n",
    "from misc import dotdict,pearson_r\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "\n",
    "model_colors = {'DNABERT':\"#D55E00\",'DNABERT-3UTR':\"#ffac6a\", \n",
    "                '13-mer':\"#CC79A7\",\n",
    "                'PhyloP-241way':\"#ffd373\",\n",
    "                'PhyloP-100way':\"#e69f00\",\n",
    "                'StateSpace':\"#0072B2\", 'StateSpace-SA':\"#59c3ff\", \n",
    "                'NTv2-250M':\"#009E73\", 'NTv2-250M-3UTR':\"#00dea2\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e82215c-3d72-4985-acbf-fd521ff920d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/lustre/groups/epigenereg01/workspace/projects/vale/mlm/half_life/agarwal_2022/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817e0df3-e2d5-4a5d-a727-ee57f2006ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_df = pd.read_csv(data_dir + 'source_data/saluki_paper/Fig3_S4/binnedgenes.txt', sep='\\t', usecols=[0,1],\n",
    "                      names=['Fold','gene_id'], skiprows=1).set_index('gene_id') #folds as they are in Agarwal article\n",
    "\n",
    "folds_df = folds_df-1 #to 0-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f664e9a-5b38-4dd2-823b-9548ad26588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_df = pd.read_csv(data_dir + 'source_data/human/seqFeatWithKmerFreqs.txt.gz', sep='\\t', \n",
    "#                                      usecols=lambda x: not 'ORF.' in x and not '5UTR.' in x) #basic features. 3'UTR and 5'UTR k-mers, ORF, target\n",
    "\n",
    "#features_df.to_parquet(data_dir + 'source_data/human/seqFeatWithKmerFreqs_no5UTR.parquet.gz')\n",
    "\n",
    "features_df = pd.read_parquet(data_dir + 'source_data/human/seqFeatWithKmerFreqs_no5UTR.parquet.gz').set_index('GENE')\n",
    "\n",
    "target_df = features_df[['HALFLIFE']]\n",
    "features_df = features_df.drop(columns='HALFLIFE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fefde16d-66de-4d65-b2cf-a43215c540e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_to_gene = pd.read_csv(data_dir + '../../UTR_coords/GRCh38_EnsembleCanonical_HGNC.tsv.gz', sep='\\t', \n",
    "                                     names=['gene_id','transcript_id'], skiprows=1,usecols=[0,1]).set_index('transcript_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102b76cb-4f0f-4056-87eb-65d119529c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get FASTA seqs\n",
    "\n",
    "human_fasta = data_dir + '../../fasta/Homo_sapiens_rna.fa'\n",
    "\n",
    "utr_df = defaultdict(str)\n",
    "\n",
    "with open(human_fasta, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('>'):\n",
    "            transcript_id = line[1:].split('.')[0]\n",
    "        else:\n",
    "            utr_df[transcript_id] += line.rstrip().upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7589c703-e38c-4d11-bfec-bc08fbb93361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utr_df = pd.DataFrame(utr_df.values(),\n",
    "             index=transcript_to_gene.loc[utr_df.keys()].gene_id, \n",
    "             columns=['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62141475-833c-4454-9c27-137e8d7686f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_params = dotdict({})\n",
    "\n",
    "input_params.model = 'dnabert' #embedding name, can be \"Species-aware\",\"\"Species-agnostic\", \"MLM\" \"word2vec\" \"griesemer\" or \"Nmers\" where N is an integer\n",
    "\n",
    "input_params.embeddings = data_dir + '../../human_3utr/embeddings/dnabert2-3utr/predictions.pickle'\n",
    "\n",
    "input_params.regressor = 'Ridge'\n",
    "\n",
    "input_params.cv_splits_hpp = 5 #number of CV splits for hyperparameter search\n",
    "input_params.seed = 1 #seed fot GroupShuffleSplit\n",
    "\n",
    "input_params.n_hpp_trials = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cd9bd8f-7745-402b-b98d-cc2064a81c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dnabert'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_features = input_params.model.split('_')[0] if '_' in input_params.model else ''\n",
    "base_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1babe65-eebf-4b44-80ff-9848eb8659d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df = [folds_df,target_df]\n",
    "\n",
    "if 'B' in base_features:\n",
    "    \n",
    "    print('adding basic features')\n",
    "    data_df.append(features_df.iloc[:,:8])\n",
    "\n",
    "if 'C' in base_features:\n",
    "\n",
    "    print('adding codons')\n",
    "    data_df.append(features_df[[x for x in features_df.columns if x.startswith('Codon.')]])\n",
    "\n",
    "if '3K' in base_features:\n",
    "\n",
    "    print(\"adding k-mer embeddings for 3'UTRs\")\n",
    "    data_df.append(features_df[[x for x in features_df.columns if x.startswith('3UTR.')]])\n",
    "\n",
    "if 'S' in base_features:\n",
    "\n",
    "    print('adding SeqWeaver RBP binding (780)')\n",
    "    for region in ('3pUTR','5pUTR','ORF'):\n",
    "        df = pd.read_csv(data_dir + f'data/human/SeqWeaver_predictions/{region}_avg.txt.gz', sep='\\t').set_index('Group.1')\n",
    "        data_df.append(df)\n",
    "\n",
    "if 'M' in base_features:\n",
    "    print('miRNA target repression (319)')\n",
    "    df = pd.read_csv(data_dir + 'data/human/CWCS.txt.gz', sep='\\t').set_index('GeneID')\n",
    "    data_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9aa53c7c-5eaf-4749-8afd-a4da0a73a56a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df = pd.concat(data_df,axis=1) #concat all features, except embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac4ac09a-ff0b-4bce-bb1c-da784565d88c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df = data_df[~data_df.HALFLIFE.isna()]\n",
    "data_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90ca9f16-a4a4-49fd-a1a5-6a32e1b43a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding language model embeddings\n",
      "number of sequences after filtering: 12981\n",
      "embeddings size: 18134\n",
      "number of sequences overlapping with embeddings: 12431\n"
     ]
    }
   ],
   "source": [
    "embeddings_df = None\n",
    "\n",
    "if input_params.embeddings!=None:\n",
    "    print('adding language model embeddings')\n",
    "    with open(input_params.embeddings,'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "        print(f'number of sequences after filtering: {len(data_df)}')\n",
    "        embeddings = np.vstack(X['embeddings'])\n",
    "        print(f\"embeddings size: {len(embeddings)}\")\n",
    "        embeddings_genes=transcript_to_gene.loc[[x.split('.')[0] for x in X['seq_names']]].gene_id\n",
    "        data_df = data_df[data_df.index.isin(embeddings_genes)]\n",
    "        embeddings_df = pd.DataFrame(embeddings, index=embeddings_genes,\n",
    "                                    columns=[f'emb_{x}' for x in range(embeddings.shape[1])])\n",
    "elif 'mers' in input_params.model:\n",
    "    \n",
    "    print('adding k-mer embeddings')\n",
    "\n",
    "    k = int(input_params.model[0])\n",
    "        \n",
    "    kmerizer = Kmerizer(k=k)\n",
    "    \n",
    "    Nmer_embeddings = utr_df.seq.apply(lambda x: kmerizer.kmerize(x))\n",
    "    \n",
    "    embeddings_df = pd.DataFrame(Nmer_embeddings.tolist(), index=Nmer_embeddings.index, columns=[f'emb_{x}' for x in range(4**k)])\n",
    "\n",
    "elif input_params.model=='word2vec':\n",
    "\n",
    "    print('adding word2vec embeddings')\n",
    "\n",
    "    kmerizer_w2v = Kmerizer(k=4)\n",
    "\n",
    "    w2v_model = gensim.models.Word2Vec(sentences=utr_df.seq.apply(lambda x: kmerizer_w2v.tokenize(x)), \n",
    "                             vector_size=128, window=5, min_count=1, workers=4, sg=1) #default: CBOW\n",
    "\n",
    "    word2vec_emb = utr_df.seq.apply(\n",
    "        lambda x: np.mean([w2v_model.wv[x]  for x in kmerizer_w2v.tokenize(x)],axis=0)) #average embedding of all 4-mers in the sequence\n",
    "\n",
    "    word2vec_emb = word2vec_emb[~word2vec_emb.isna()]\n",
    "    \n",
    "    embeddings_df = pd.DataFrame(word2vec_emb.tolist(), index=word2vec_emb.index, columns=[f'emb_{x}' for x in range(128)])\n",
    "\n",
    "if embeddings_df is not None:\n",
    "    data_df = data_df.join(embeddings_df)\n",
    "    print(f'number of sequences overlapping with embeddings: {len(data_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b97eeb67-7133-4ead-bcb9-b72b0749164c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data_df.drop(columns=['Fold','HALFLIFE']).values#all columns except HALFLIFE and fold\n",
    "\n",
    "y = data_df['HALFLIFE'].values\n",
    "\n",
    "folds = data_df['Fold'].values\n",
    "\n",
    "genes = data_df.index\n",
    "\n",
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fc5beaf-d2ee-45ad-a40f-309609edff82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hpp_search_svr(X,y,groups,cv_splits = 5):\n",
    "\n",
    "    '''\n",
    "    Perform Hyperparameter Search using OPTUNA Bayesian Optimisation strategy\n",
    "\n",
    "    The bets hyperparameters should maximize coefficient of determination (R2)\n",
    "\n",
    "    The hyperparameter range should first be adjused with grid search to make the BO algorithm converge in reasonable time\n",
    "    '''\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        C = trial.suggest_float(\"C\", 1e-2, 1, log=True)\n",
    "        epsilon = trial.suggest_float(\"epsilon\", 1e-5, 1, log=True)\n",
    "        gamma = trial.suggest_float(\"gamma\", 1e-5, 1, log=True)\n",
    "\n",
    "        pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(),\n",
    "                                                  sklearn.svm.SVR(C=C, epsilon=epsilon, gamma=gamma))\n",
    "        \n",
    "        with parallel_backend('multiprocessing', n_jobs=input_params.n_jobs):\n",
    "            cv_score = sklearn.model_selection.cross_val_score(pipe, X, y, groups=groups,\n",
    "                     cv = cv_splits, scoring = 'r2', n_jobs = -1)\n",
    "\n",
    "        av_score = cv_score.mean()\n",
    "\n",
    "        return av_score\n",
    "\n",
    "    #optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "\n",
    "    study = optuna.create_study(direction = \"maximize\")\n",
    "\n",
    "    study.optimize(objective, n_trials = input_params.n_hpp_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd15461-1efb-4ad0-b8c5-f11efba5760a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hpp_dict = {}\n",
    "\n",
    "#best_hpp_models = {'Species-aware-BC3MS':{'C': 17.2, 'epsilon': 0.73, 'gamma': 2e-4},\n",
    "#            'Species-agnostic-BC3MS':{'C': 15.3, 'epsilon': 0.37, 'gamma': 1.8e-4},\n",
    "#            'NT-MS-v2-500M-BC3MS':{'C': 100, 'epsilon': 0.84, 'gamma': 1.3e-5},\n",
    "#            'DNABERT-2-BC3MS':{'C': 19, 'epsilon': 9.8e-5, 'gamma': 1.4e-4},\n",
    "#            'DNABERT-2-B3': {'C': 100, 'epsilon': 2e-3, 'gamma': 6.6e-05},\n",
    "#            'BCMS': {'C': 18.5, 'epsilon': 2.8e-2, 'gamma': 1.3e-4},\n",
    "#            'Species-agnostic-B3':{'C': 86, 'epsilon': 0.06, 'gamma': 2.4e-4},\n",
    "#            'Species-agnostic-3':{'C': 22, 'epsilon': 0.003, 'gamma': 5.6e-4},\n",
    "#            'Species-aware-3':{'C': 2.05, 'epsilon': 0.091, 'gamma': 0.0037},\n",
    "#            '3K': {'C': 8.7, 'epsilon': 1.8e-3, 'gamma': 4.2e-05},\n",
    "#            'DNABERT-2-3': {'C': 0.69, 'epsilon': 2.6e-4, 'gamma': 6.3e-4},\n",
    "#            'NT-MS-v2-500M-3':{'C': 21, 'epsilon': 0.75, 'gamma': 3.8e-05},\n",
    "#           }\n",
    "\n",
    "res_df = []\n",
    "\n",
    "N_folds = folds.max()+1\n",
    "\n",
    "for fold in range(N_folds):\n",
    "    \n",
    "        print(f'Fold {fold}')\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = X[folds!=fold],X[folds==fold],y[folds!=fold],y[folds==fold]\n",
    "\n",
    "        if input_params.regressor == 'Ridge':\n",
    "            pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(), \n",
    "                                              sklearn.linear_model.RidgeCV(cv=input_params.cv_splits_hpp, alphas=10.**np.arange(-5,6)))\n",
    "        \n",
    "        elif input_params.regressor == 'SVR':\n",
    "            pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(),\n",
    "                                                  sklearn.svm.SVR(**hpp_dict))\n",
    "        \n",
    "        pipe.fit(X_train,y_train)\n",
    "                    \n",
    "        y_pred = pipe.predict(X_test) \n",
    "                \n",
    "        fold_res = np.vstack([np.ones((len(y_test),))*fold,genes[folds==fold],y_test,y_pred]).T\n",
    "\n",
    "        res_df.append(fold_res)\n",
    "\n",
    "res_df = np.vstack(res_df)\n",
    "res_df = pd.DataFrame(res_df,columns=['fold','gene','y_true','y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba5c49e9-2a38-4411-83df-6a6618cdf9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.301991737176074"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_r(res_df.y_true,res_df.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93970bc4-68fc-4209-989f-c796a1728cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cv_scores.to_csv(data_dir + f'predictions/{input_params.model}.tsv', sep = '\\t', index=None)\n",
    "res_df.to_csv(data_dir + f'predictions/{input_params.model}-full.tsv', sep = '\\t', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
