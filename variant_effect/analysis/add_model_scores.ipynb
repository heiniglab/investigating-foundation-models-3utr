{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb58da27-c136-44c2-bd19-0854512e54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "sys.path.append(\"/home/icb/sergey.vilov/workspace/MLM/utils\") \n",
    "from misc import model_alias, rna_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890b6ff8-30b1-4bbc-b666-dce036d99786",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/lustre/groups/epigenereg01/workspace/projects/vale/mlm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52cf453-0244-42af-8677-6dfd7f498524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(fasta):\n",
    "\n",
    "    seqs = defaultdict(str)\n",
    "    \n",
    "    with open(fasta, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                seq_name = line[1:].rstrip()\n",
    "            else:\n",
    "                seqs[seq_name] += line.rstrip().upper()\n",
    "    return seqs\n",
    "\n",
    "def reverse_complement(seq):\n",
    "    '''\n",
    "    Take sequence reverse complement\n",
    "    '''\n",
    "    compl_dict = {'A':'T', 'C':'G', 'G':'C', 'T':'A','a':'t', 'c':'g', 'g':'c', 't':'a'}\n",
    "    compl_seq = ''.join([compl_dict.get(x,x) for x in seq])\n",
    "    rev_seq = compl_seq[::-1]\n",
    "    return rev_seq\n",
    "\n",
    "def get_auc(df,model_name,scores):\n",
    "    dataset_scores = {}\n",
    "    for score_name in scores:\n",
    "        if model_name+'-'+score_name in df.columns:\n",
    "            y = df.label.values\n",
    "            X = df[model_name+'-'+score_name].values\n",
    "            y = y[~np.isnan(X)]\n",
    "            X = X[~np.isnan(X)]\n",
    "            score = roc_auc_score(y,X)\n",
    "            dataset_scores[model_name+'-'+score_name] = max(score,1-score)\n",
    "    return pd.Series(dataset_scores)\n",
    "\n",
    "mapping = {'A':0,'C':1,'G':2,'T':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc93251-85eb-4de4-b899-04d2ea3a7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_probas(glob_path):\n",
    "    res = {}\n",
    "    for probas_file in glob(glob_path):\n",
    "        #print(probas_file)\n",
    "        with open(probas_file, 'rb') as f:\n",
    "            fold_res = pickle.load(f)\n",
    "            if 'left_shift' not in fold_res.keys():\n",
    "                fold_res['left_shift'] = np.zeros((len(fold_res['seq_names']),1))\n",
    "            fold_res = {seq_name:{'probs':prob,'seq':seq,'left_shift':left_shift} for seq_name,prob,seq,left_shift in zip(fold_res['seq_names'],fold_res['probs'],fold_res['seqs'],fold_res['left_shift'])}\n",
    "            res.update(fold_res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c12ae4-4e08-4881-958a-dc96e0d0db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_scores(model_name, model_preds):\n",
    "    \n",
    "    epsilon=1e-14\n",
    "\n",
    "    n_var_added = 0\n",
    "\n",
    "    res = defaultdict(dict)\n",
    "\n",
    "    df =  utr_variants.drop_duplicates(subset='var_id').set_index('var_id')\n",
    "    \n",
    "    for var_id, var in tqdm(df.iterrows(), total=len(df),bar_format='{bar}|{percentage:3.0f}%'):\n",
    "        \n",
    "        if var.vartype=='SNP':\n",
    "            \n",
    "            altseq, altprobs = None, None\n",
    "            \n",
    "            if var_id + '_ref' in model_preds.keys():\n",
    "                \n",
    "                refseq = model_preds[var_id + '_ref']['seq']\n",
    "                refprobs = model_preds[var_id + '_ref']['probs'][:,:4]\n",
    "\n",
    "                if var_id + '_alt' in model_preds.keys():\n",
    "                    altseq = model_preds[var_id + '_alt']['seq']\n",
    "                    altprobs = model_preds[var_id + '_alt']['probs'][:,:4] \n",
    "\n",
    "                if refseq.isupper():\n",
    "                    varpos_rel = len(refseq)//2\n",
    "                else:\n",
    "                    varpos_rel = [idx for idx,c in enumerate(refseq) if c.islower()][0]\n",
    "                    if model_name in rna_models and var.strand=='-':\n",
    "                        varpos_rel = len(refseq)-varpos_rel-1\n",
    "                    \n",
    "            elif var.seq_name in model_preds.keys():\n",
    "\n",
    "                refseq = model_preds[var.seq_name]['seq']        \n",
    "                refprobs = model_preds[var.seq_name]['probs'][:,:4]\n",
    "\n",
    "                varpos_rel = var.pos_rel\n",
    "                \n",
    "            else:\n",
    "\n",
    "                continue  \n",
    "\n",
    "            if model_name in rna_models and var.strand=='-':\n",
    "    \n",
    "                refseq = reverse_complement(refseq)\n",
    "                refprobs = refprobs[::-1,[3,2,1,0]]\n",
    "\n",
    "                if altseq:\n",
    "                    altseq = reverse_complement(altseq)\n",
    "                    altprobs = altprobs[::-1,[3,2,1,0]]\n",
    "\n",
    "            assert refseq[varpos_rel].upper() == var.ref, f'{var}'\n",
    "            refprobs = refprobs/refprobs.sum(1,keepdims=1)\n",
    "\n",
    "            if altseq:\n",
    "                \n",
    "                assert altseq[varpos_rel].upper() == var.alt\n",
    "                altprobs = altprobs/altprobs.sum(1,keepdims=1)\n",
    "                \n",
    "                dependency = np.max(abs(\n",
    "                            (np.log2(refprobs+epsilon)-np.log2(1-refprobs+epsilon))\n",
    "                            -(np.log2(altprobs+epsilon)-np.log2(1-altprobs+epsilon))\n",
    "                                       )\n",
    "                                 ,1)\n",
    "\n",
    "                #R = min(varpos_rel,len(dependency)-varpos_rel)\n",
    "                #\n",
    "                #if R>0:\n",
    "                #    vis = np.stack((dependency[varpos_rel-R:varpos_rel],\n",
    "                #                        dependency[varpos_rel:varpos_rel+R])).mean()\n",
    "\n",
    "                vis = np.delete(dependency,varpos_rel).mean()\n",
    "                \n",
    "                res[var_id][model_name+'-VIS'] = vis\n",
    "\n",
    "            else:\n",
    "                \n",
    "                refprob = refprobs[varpos_rel][mapping[var.ref]]\n",
    "                altprob = refprobs[varpos_rel][mapping[var.alt]]\n",
    "                \n",
    "                res[var_id][model_name+'-palt_inv'] = -np.log(altprob+1e-14)\n",
    "                res[var_id][model_name+'-pref'] = np.log(refprob+1e-14)\n",
    "                #utr_variants.at[var_idx, model_name+'-pratio'] = np.log(refprob+epsilon)-np.log(altprob+epsilon)\n",
    "\n",
    "            n_var_added += 1\n",
    "\n",
    "    res = pd.DataFrame(res.values(),index=res.keys())\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a54b846-18b8-4de3-ba3d-78dc16a9b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "utr_variants = pd.read_csv(data_dir+'variants/selected/variants_snp.tsv', sep='\\t') \n",
    "\n",
    "utr_variants['pos_rel'] = utr_variants.pos-utr_variants.seq_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab9f28-6fac-4d00-811a-20f46881e0ab",
   "metadata": {},
   "source": [
    "# Conservation-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c06c30-076f-4b52-9d46-4716854f433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ('PhyloP-100way','PhyloP-241way'):\n",
    "    phylop_res = pd.read_csv(data_dir + f'variants/prefiltered/PhyloP/{model}.3utr.scores.tsv.gz', sep='\\t',\n",
    "                           header = None, names=['chrom','pos',f'{model}-score'])\n",
    "    \n",
    "    phylop_res.pos = phylop_res.pos-1 #to 0-based\n",
    "    \n",
    "    utr_variants = utr_variants.merge(phylop_res,how='left')\n",
    "    \n",
    "    del phylop_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0426ec-c0b5-461a-b6c2-e6414cfc4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add CADD 1.7 scores\n",
    "\n",
    "for vartype in ('snps',):\n",
    "    cadd_res = pd.read_csv(data_dir + f'variants/prefiltered/CADD/CADD.3utr.{vartype}.scores.tsv.gz', sep='\\t',\n",
    "                           header = None, names=['chrom','pos','ref','alt','CADD-raw','CADD-phred'])\n",
    "    \n",
    "    cadd_res.pos = cadd_res.pos-1 #to 0-based\n",
    "    \n",
    "    utr_variants = utr_variants.merge(cadd_res,how='left').drop_duplicates()\n",
    "    \n",
    "    del cadd_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b6d8bb-8376-4905-ac3a-74ea47ae12db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c1e08-28f2-42f4-9594-f97eb13a1103",
   "metadata": {},
   "source": [
    "# Scores from LM probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab824339-7975-46b2-a2c4-b34a4f202903",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_path = data_dir + 'human_3utr/probs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d49ec4db-361d-4dac-a9b5-a43ac7cb2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoo-AL\n",
      "Zoo-AL loaded, 18178 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70261 variants added\n",
      "DNABERT\n",
      "DNABERT loaded, 18134 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70097 variants added\n",
      "DNBT-3UTR-RNA\n",
      "DNBT-3UTR-RNA loaded, 18134 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70097 variants added\n",
      "NT-MS-v2-100M\n",
      "NT-MS-v2-100M loaded, 18178 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70261 variants added\n",
      "NT-3UTR-RNA\n",
      "NT-3UTR-RNA loaded, 18134 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70097 variants added\n",
      "STSP-3UTR-RNA\n",
      "STSP-3UTR-RNA loaded, 18134 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70097 variants added\n",
      "STSP-3UTR-RNA-SA\n",
      "STSP-3UTR-RNA-SA loaded, 18134 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70097 variants added\n",
      "STSP-3UTR-DNA\n",
      "STSP-3UTR-DNA loaded, 18178 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70261 variants added\n",
      "STSP-3UTR-RNA-HS\n",
      "STSP-3UTR-RNA-HS loaded, 18134 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70097 variants added\n"
     ]
    }
   ],
   "source": [
    "for model_name in ('Zoo-AL','DNABERT', 'DNBT-3UTR-RNA', 'NT-MS-v2-100M', 'NT-3UTR-RNA',\n",
    "                   'STSP-3UTR-RNA','STSP-3UTR-RNA-SA','STSP-3UTR-DNA','STSP-3UTR-RNA-HS',):\n",
    "\n",
    "    print(model_name)\n",
    "    \n",
    "    model_probas = get_model_probas(probs_path + '/' + model_alias[model_name] + '/predictions*.pickle')\n",
    "    \n",
    "    print(f'{model_name} loaded, {len(model_probas)} sequences')\n",
    "    \n",
    "    res = get_model_scores(model_name, model_probas)\n",
    "\n",
    "    n_var_added = utr_variants.var_id.isin(res.index).sum()\n",
    "\n",
    "    if n_var_added>0:\n",
    "        utr_variants=utr_variants.merge(res.reset_index(names='var_id'),how='left')\n",
    "    \n",
    "    print(n_var_added, 'variants added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a4619b-e711-4c0d-9460-df917e3017d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero_shot_dir = data_dir + 'variants/zero-shot-probs'\n",
    "#\n",
    "#\n",
    "#zero_shot_dir_models = {'NT-3UTR-RNA': zero_shot_dir,\n",
    "#                 'NT-MS-v2-100M': zero_shot_dir,\n",
    "#                 'DNABERT': zero_shot_dir,\n",
    "#                 'DNBT-3UTR-RNA': zero_shot_dir,\n",
    "#                 'STSP-3UTR-RNA': data_dir + 'variants/embeddings/', \n",
    "#                 'STSP-3UTR-RNA-SA': data_dir + 'variants/embeddings/',\n",
    "#                 'STSP-3UTR-DNA': data_dir + 'variants/embeddings/', \n",
    "#                 'STSP-3UTR-RNA-HS': data_dir + 'variants/embeddings/',\n",
    "#                 'Zoo-AL': data_dir + 'human_3utr/probs/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec406693-356b-4d69-b5c1-4d2b03c62bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for model_name in ('Zoo-AL','DNABERT', 'DNBT-3UTR-RNA', 'NT-MS-v2-100M', 'NT-3UTR-RNA',\n",
    "#                   'STSP-3UTR-RNA','STSP-3UTR-RNA-SA','STSP-3UTR-DNA','STSP-3UTR-RNA-HS',):\n",
    "#\n",
    "#    print(model_name)\n",
    "#    \n",
    "#    model_probas = get_model_probas(zero_shot_dir_models[model_name] + '/' + model_alias[model_name] + '/predictions*.pickle')\n",
    "#    model_probas = {k:v for k,v in model_probas.items() if not k.endswith('_alt') }\n",
    "#\n",
    "#    print(f'{model_name} loaded, {len(model_probas)} sequences')\n",
    "#    \n",
    "#    res = get_model_scores(model_name, model_probas)\n",
    "#\n",
    "#    #res.columns = [x + '-zs' for x in res.columns]\n",
    "#\n",
    "#    n_var_added = utr_variants.var_id.isin(res.index).sum()\n",
    "#\n",
    "#    if n_var_added>0:\n",
    "#        utr_variants=utr_variants.merge(res.reset_index(names='var_id'),how='left')\n",
    "#\n",
    "#    print(n_var_added, 'variants added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b282ba0-d76c-4ee3-a8d5-d98f57e559b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_alias.keys():\n",
    "    if model_name+'-palt_inv' in utr_variants.columns:\n",
    "        utr_variants[model_name+'-pratio'] = utr_variants[model_name+'-pref']+utr_variants[model_name+'-palt_inv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5730bc83-aeb8-4a1b-8879-c47f7f73ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores=('pref','pratio','pref-zs','pratio-zs','score','raw')\n",
    "#scores=('pratio','score','raw')\n",
    "#res = []\n",
    "#\n",
    "#for model_name in ('Zoo-AL','DNABERT', 'DNABERT-3UTR', 'NT-MS-v2-100M', 'NTv2-100M-3UTR',\n",
    "#                   'StateSpace', 'StateSpace-SA'):\n",
    "#for model_name in ('NT-MS-v2-100M','NTv2-100M-3UTR','NTv2-100M-3UTR*','Zoo-AL','CADD','PhyloP-241way','PhyloP-100way'):\n",
    "#    \n",
    "#    res_model = utr_variants.groupby(['split']).apply(lambda x:get_auc(x,model_name,scores)).loc[['clinvar','gnomAD','eQTL-susie','CADD']]\n",
    "#    res.append(res_model)\n",
    "#\n",
    "#pd.concat(res,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844050a-0074-4795-bf1b-18fa9816480d",
   "metadata": {},
   "source": [
    "# Variant influence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5a53ab5-6f40-4d7f-a644-d368b8f4b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dir = data_dir + '/variants/variant_influence_score/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4275b676-ff10-49c8-b838-782bb6c4d0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNABERT\n",
      "DNABERT loaded, 30518 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21285 variants added\n",
      "DNBT-3UTR-RNA\n",
      "DNBT-3UTR-RNA loaded, 30518 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21285 variants added\n",
      "NT-MS-v2-100M\n",
      "NT-MS-v2-100M loaded, 30518 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21285 variants added\n",
      "NT-3UTR-RNA\n",
      "NT-3UTR-RNA loaded, 30518 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21285 variants added\n",
      "STSP-3UTR-RNA\n",
      "STSP-3UTR-RNA loaded, 30518 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21285 variants added\n",
      "STSP-3UTR-RNA-SA\n",
      "STSP-3UTR-RNA-SA loaded, 30518 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21285 variants added\n",
      "STSP-3UTR-DNA\n",
      "STSP-3UTR-DNA loaded, 30518 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21285 variants added\n",
      "STSP-3UTR-RNA-HS\n",
      "STSP-3UTR-RNA-HS loaded, 30518 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21285 variants added\n"
     ]
    }
   ],
   "source": [
    "for model_name in ('DNABERT', 'DNBT-3UTR-RNA', 'NT-MS-v2-100M', 'NT-3UTR-RNA',\n",
    "                   'STSP-3UTR-RNA','STSP-3UTR-RNA-SA','STSP-3UTR-DNA','STSP-3UTR-RNA-HS',):\n",
    "    \n",
    "    print(model_name)\n",
    "    \n",
    "    if model_name in rna_models:\n",
    "        vis_fa = data_dir + '/variants/selected/variants_rna.fa'\n",
    "    else:\n",
    "        vis_fa = data_dir + '/variants/selected/variants_dna_fwd.fa'\n",
    "    \n",
    "    vis_fasta = read_fasta(vis_fa)\n",
    "    \n",
    "    vis_predictions_path = vis_dir + model_alias[model_name] + '/predictions*'\n",
    "    model_probas =  get_model_probas(vis_predictions_path)\n",
    "    \n",
    "    print(f'{model_name} loaded, {len(model_probas)} sequences')\n",
    "    \n",
    "    res = get_model_scores(model_name, model_probas)\n",
    "\n",
    "    n_var_added = utr_variants.var_id.isin(res.index).sum()\n",
    "\n",
    "    if n_var_added>0:\n",
    "        utr_variants=utr_variants.merge(res.reset_index(names='var_id'),how='left')\n",
    "\n",
    "    print(n_var_added, 'variants added')\n",
    "    #utr_variants.rename(columns={model_name+'-'+score:model_name+'-'+score+'_vis' for score in ('palt','pref','pratio')},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cedce-2182-47a7-b532-3634d1ea9836",
   "metadata": {},
   "source": [
    "# Scores from embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7cfdca6-09cf-4ae7-b230-95e0fe04b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings_score(seq_names,embeddings,losses,model_name):\n",
    "    res = []\n",
    "    #loss_ref_avg, loss_ref_central, loss_alt_avg, loss_alt_central = None, None, None, None #we don't compute score base on losses here\n",
    "    for idx in range(0,len(embeddings),2):\n",
    "        assert seq_names[idx]==seq_names[idx+1].replace('alt','ref')\n",
    "        emb_ref, emb_alt = embeddings[idx], embeddings[idx+1]\n",
    "        l2 = np.linalg.norm(emb_ref-emb_alt)\n",
    "        l1 = np.linalg.norm((emb_ref-emb_alt), ord=1)\n",
    "        dot = np.dot(emb_ref,emb_alt)\n",
    "        cosine = dot/(np.linalg.norm(emb_ref)*np.linalg.norm(emb_alt))\n",
    "        loss_ref, loss_alt = losses[idx], losses[idx+1]\n",
    "        varname = seq_names[idx].replace('_ref','').split('_')\n",
    "        res.append((varname[0],int(varname[1]),varname[2],varname[3],l1,l2,dot,cosine,loss_ref,loss_alt))\n",
    "    res = pd.DataFrame(res,columns=['chrom','pos','ref','alt',\n",
    "        f'{model_name}-l1',f'{model_name}-l2',f'{model_name}-dot',f'{model_name}-cosine',\n",
    "        f'{model_name}-loss_ref', f'{model_name}-loss_alt'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e4c2ebe-4ea9-4d18-88ba-5904e4a3ba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNABERT\n",
      "70261 variants added\n",
      "DNBT-3UTR-RNA\n",
      "70261 variants added\n",
      "DNABERT2\n",
      "70261 variants added\n",
      "DNABERT2-ZOO\n",
      "70261 variants added\n",
      "DNBT2-3UTR-RNA\n",
      "70261 variants added\n",
      "NT-MS-v2-100M\n",
      "70261 variants added\n",
      "NT-3UTR-RNA\n",
      "70261 variants added\n",
      "STSP-3UTR-RNA\n",
      "70261 variants added\n",
      "STSP-3UTR-RNA-SA\n",
      "70261 variants added\n",
      "STSP-3UTR-DNA\n",
      "70261 variants added\n",
      "STSP-3UTR-RNA-HS\n",
      "70261 variants added\n"
     ]
    }
   ],
   "source": [
    "emb_dir  = data_dir + 'variants/embeddings/'\n",
    "\n",
    "for model_name in ('DNABERT','DNBT-3UTR-RNA','DNABERT2','DNABERT2-ZOO','DNBT2-3UTR-RNA','NT-MS-v2-100M',\n",
    "         'NT-3UTR-RNA','STSP-3UTR-RNA','STSP-3UTR-RNA-SA','STSP-3UTR-DNA','STSP-3UTR-RNA-HS',):\n",
    "\n",
    "    print(model_name)\n",
    "    \n",
    "    with open(emb_dir + model_alias[model_name] + '/predictions.pickle', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    embeddings_scores = compute_embeddings_score(data['seq_names'],data['embeddings'], data['losses'],model_name)\n",
    "\n",
    "    embeddings_scores[model_name+'-loss_diff'] = embeddings_scores[model_name+'-loss_alt']-embeddings_scores[model_name+'-loss_ref']\n",
    "\n",
    "    utr_variants = utr_variants.merge(embeddings_scores, how='left')\n",
    "\n",
    "    n_var_added = (~(utr_variants[model_name+'-l1']).isna()).sum()\n",
    "\n",
    "    print(n_var_added, 'variants added')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbb298-03d5-4a46-b729-094f66c635e7",
   "metadata": {},
   "source": [
    "# Scores from supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93196f12-8e45-4caf-9b65-9c834be674b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNABERT\n",
      "70261 variants added\n",
      "DNBT-3UTR-RNA\n",
      "70261 variants added\n",
      "DNABERT2\n",
      "70261 variants added\n",
      "DNABERT2-ZOO\n",
      "70261 variants added\n",
      "DNBT2-3UTR-RNA\n",
      "70261 variants added\n",
      "NT-MS-v2-100M\n",
      "70261 variants added\n",
      "NT-3UTR-RNA\n",
      "70261 variants added\n",
      "STSP-3UTR-RNA\n",
      "70261 variants added\n",
      "STSP-3UTR-RNA-SA\n",
      "70261 variants added\n",
      "STSP-3UTR-DNA\n",
      "70261 variants added\n",
      "STSP-3UTR-RNA-HS\n",
      "70261 variants added\n"
     ]
    }
   ],
   "source": [
    "for classifier in ('MLP',):#('LogisticRegression','MLP'):\n",
    "    \n",
    "    pred_dir  = data_dir + f'variants/predictions/merge_embeddings_1/{classifier}/'\n",
    "\n",
    "    for model_name in ('DNABERT','DNBT-3UTR-RNA','DNABERT2','DNABERT2-ZOO','DNBT2-3UTR-RNA','NT-MS-v2-100M',\n",
    "         'NT-3UTR-RNA','STSP-3UTR-RNA','STSP-3UTR-RNA-SA','STSP-3UTR-DNA','STSP-3UTR-RNA-HS',):\n",
    "    \n",
    "        print(model_name)\n",
    "\n",
    "        model_res = []\n",
    "\n",
    "        for subset in ('CADD','clinvar','gnomAD','eQTL-susie',):\n",
    "\n",
    "            pred_res = pred_dir + subset  + '-' + model_alias[model_name] + '.tsv'\n",
    "            \n",
    "            if os.path.isfile(pred_res):\n",
    "                subset_df = pd.read_csv(pred_res,sep='\\t')\n",
    "                model_res.append(subset_df)\n",
    "            else:\n",
    "                print(pred_res)\n",
    "\n",
    "        if len(model_res)>0:\n",
    "            model_res = pd.concat(model_res)\n",
    "            model_res.rename(columns={'y_pred':model_name+'-'+classifier},inplace=True)\n",
    "            utr_variants = utr_variants.merge(model_res,how='left')\n",
    "            \n",
    "            n_var_added = (~(utr_variants[model_name+'-'+classifier]).isna()).sum()\n",
    "                \n",
    "            print(n_var_added, 'variants added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f5dc786-4dde-4c39-ad06-996eeb13521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utr_variants.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03d843b3-a711-4651-b05c-5cd66ee5e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "utr_variants.to_csv(data_dir + 'all_scores/variant_scores.tsv.gz', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca0d9c-5f9b-4d8e-91a4-dd5bd639baed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
