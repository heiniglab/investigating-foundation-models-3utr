{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f03e8bb-e534-4836-9702-11275bc430a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import multiprocess as mp\n",
    "from multiprocess import Pool\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45388003-47fa-4fca-9b0c-ceddd9a8cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f5de56-107b-490a-aaa7-bf02a85b70d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8342bd-8723-451e-ac33-57c1ca47080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../mpra_griesemer/regression/hpp_search_1st.pickle','rb') as f:\n",
    "    data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65fd3f75-d031-4e50-9270-b75e3f641a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['X'], data['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ab6d59-77ea-47d2-a29b-5e62525d0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_regressor import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "662517a3-7b6e-4111-9cba-cb8ea84017d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5560672480397102\n",
      "41.9 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "M = MLPRegressor(p_dropout=0.2,weight_decay=0,lr=1e-3\n",
    "                 ,batch_size=4096,hidden_layer_sizes=(1024,128,32))\n",
    "\n",
    "M.set_params(N_epochs=300)\n",
    "\n",
    "M.fit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(M.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb63e96-a8e0-44a5-931c-02480f2e6812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t,v = zip(*M.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff93588-3758-4583-9859-f9e152336364",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(v[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9f2e7-4dfa-4d87-9c61-1091ed0485e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(v)\n",
    "ax.plot(t)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da8fcdb-52bf-41ae-a0af-a3314c25aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_regression(args):\n",
    "\n",
    "    import sklearn.preprocessing\n",
    "    import sklearn.pipeline\n",
    "    import sklearn.svm\n",
    "    from mlp_regressor import MLPRegressor\n",
    "    \n",
    "    X_train, y_train, X_test,y_test = args\n",
    "\n",
    "    best_hpp =  {'C': 4.057, 'epsilon': 0.39, 'gamma': 0.0046}\n",
    "    pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(),\n",
    "                                                  sklearn.svm.SVR(**best_hpp))\n",
    "    #pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(),\n",
    "    #                                              MLPRegressor(p_dropout=0.5,weight_decay=0,lr=5e-4,\n",
    "    #                                                            batch_size=1024,hidden_layer_sizes=(1024,128,32)))\n",
    "\n",
    "    pipe.fit(X_train,y_train)\n",
    "        \n",
    "    y_pred = pipe.predict(X_test)\n",
    "                \n",
    "    print('done')\n",
    "\n",
    "    return (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e7154a3-78e8-46c2-915a-7872b101ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=sklearn.model_selection.KFold(n_splits=5)\n",
    "\n",
    "def run_pool():\n",
    "    \n",
    "    all_res = []\n",
    "    \n",
    "    pool = Pool(processes=8,maxtasksperchild=3)\n",
    "\n",
    "    for res in pool.imap(apply_regression,((X_train[train_idx],y_train[train_idx],X_train[test_idx],y_train[test_idx]) \n",
    "                                           for train_idx,test_idx in kfold.split(X_train,y_train))):\n",
    "        all_res.extend(res)\n",
    "     \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return all_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8518374-d1e0-41b2-acb5-62190b43d716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "56 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "all_res = run_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1c230c5-1f6f-43b2-90b4-3a971be3c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn.neural_network\n",
    "\n",
    "M=sklearn.neural_network.MLPRegressor(hidden_layer_sizes=(1024,128,32,), \n",
    "                                      solver='adam', \n",
    "                                      alpha=0., batch_size=1024, \n",
    "                                      learning_rate='constant', \n",
    "                                      learning_rate_init=5e-4, \n",
    "                                      power_t=0.5, max_iter=500, \n",
    "                                      shuffle=True, random_state=42, \n",
    "                                      tol=0.0001, verbose=True, \n",
    "                                      warm_start=False, \n",
    "                                      momentum=0.9, nesterovs_momentum=True, \n",
    "                                      early_stopping=False, \n",
    "                                      validation_fraction=0., \n",
    "                                      n_iter_no_change=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0539477-fe09-4b65-8f6e-5944f0e0b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "M.fit(X_train, y_train)\n",
    "\n",
    "y_pred=M.predict(X_test)\n",
    "\n",
    "pearson_r(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee9c12e-6316-478c-af24-6f2cf1ffc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, layer_sizes=(769,64,32,16,), \n",
    "                 p_dropout=0):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        model_layers = []\n",
    "        \n",
    "        for layer_idx in range(len(layer_sizes)-1):\n",
    "            model_layers.extend((nn.Linear(layer_sizes[layer_idx],layer_sizes[layer_idx+1]), nn.Dropout(p_dropout), nn.ReLU(),))\n",
    "        model_layers.append(nn.Linear(layer_sizes[-1],1))\n",
    "        self.model = nn.Sequential(*model_layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed928415-8048-4c86-a9be-3f25f92b05c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 16s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "def pearson_r_scorer(y_true, y_pred):\n",
    "    y_true = y_true.detach().numpy()\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    return pearson_r(y_true, y_pred) ** 2 \n",
    "\n",
    "def train(model,X_train, y_train, X_val=None, y_val=None, \n",
    "          weight_decay=0, lr=5e-4,\n",
    "          N_epochs=100,batch_size=1024, scorer=pearson_r_scorer):\n",
    "    \n",
    "    # Construct data_loader, optimizer, etc.\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    if X_val is not None:\n",
    "        X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "        y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), weight_decay=weight_decay, lr=lr)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    history = []\n",
    "\n",
    "    batches_per_epoch = int(np.ceil(len(X_train)//batch_size))\n",
    "\n",
    "    for epoch in range(N_epochs):\n",
    "        train_score, val_score = 0, None\n",
    "        for batch_idx in range(batches_per_epoch):\n",
    "            # take a batch\n",
    "            X_batch = X_train[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "            y_batch = y_train[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch).reshape(-1)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            train_score += scorer(y_batch, y_pred)/batches_per_epoch\n",
    "        if X_val is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(X_val).reshape(-1)\n",
    "            val_score = scorer(y_val, y_pred)\n",
    "        history.append((train_score,val_score))\n",
    "\n",
    "def run_parallel():\n",
    "    num_processes = 5\n",
    "    model = MLPRegressor()\n",
    "    # NOTE: this is required for the ``fork`` method to work\n",
    "    model.share_memory()\n",
    "    processes = []\n",
    "    for rank in range(num_processes):\n",
    "        p = mp.Process(target=train, args=(model,X_train,y_train))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "run_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbd9dc-302d-4b1b-a86d-ea5d61b7ec6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd00857-728a-4a5d-973b-3bcce55c22ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73c74c-ce5f-4f6a-bcd2-f82ab039ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = run_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7919bd4-32ee-4fdb-9a7d-dd27a5990fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca121d3-2c78-4aab-aece-8f8350446cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aaa258-dc51-4ae5-9a70-6cb091b79f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(range(0,105,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e63ce-bd56-4e0b-8f84-43e4d657fc1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "p_dropout = 0.\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(128, 64),\n",
    "    nn.Dropout(p_dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.Dropout(p_dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.Dropout(p_dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 1)\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# train-test split of the dataset\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=1)\n",
    "train_index, test_index = next(iter(gss.split(X, y, groups)))\n",
    "X_train, X_test, y_train, y_test = X[train_index,:],X[test_index,:],y[train_index],y[test_index]\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    " \n",
    "# training parameters\n",
    "n_epochs = 1000   # number of epochs to run\n",
    "batch_size = 1000  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_score = -np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=False) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            train_score = pearson_r2(y_batch, y_pred)\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    test_score = pearson_r2(y_test, y_pred)\n",
    "    bar.set_postfix(r2_train=train_score)\n",
    "    print(train_score,test_score)\n",
    "    history.append(test_score)\n",
    "    if test_score < best_score:\n",
    "        best_mse = test_score\n",
    "        best_weights = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b47ca-8ed4-4016-a094-7f738ceb1364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred.detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184e477-4f94-4eb1-8052-6f4cfa0ed552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e62c43-c054-46b0-af8e-993e153338e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
