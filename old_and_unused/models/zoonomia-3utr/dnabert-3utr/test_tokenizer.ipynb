{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3090192e-7258-4b58-a01f-22023fbaf4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from helpers.tokenization_dna import DNATokenizer\n",
    "import pysam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74b01b8-ded4-4d96-bb68-c3defeebe381",
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = '/lustre/groups/epigenereg01/workspace/projects/vale/mlm/fasta/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0552904c-0cbe-4261-a8eb-4c7e388872fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = DNATokenizer(vocab_file='../DNABERT/src/transformers/dnabert-config/bert-config-6/vocab.txt',\n",
    "                        max_len=510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67627f16-a363-4600-84b3-9fb9e975fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmers_stride1(seq, k=6):\n",
    "    # splits a sequence into overlapping k-mers\n",
    "    return [seq[i:i + k] for i in range(0, len(seq)-k+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57555059-4876-4b6e-8b33-e72e1dbc5138",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 510\n",
    "overlap_bp = 128\n",
    "max_seq_len = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112f80b-5911-418a-8086-5daf8d14b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = workdir + '241_mammals.shuffled.fa'\n",
    "\n",
    "seq_names = pd.read_csv(fa + '.fai', sep='\\t', header=None, usecols=[0])[0].squeeze().values\n",
    "\n",
    "fasta = pysam.FastaFile(fa)\n",
    "\n",
    "data = []\n",
    "\n",
    "def seq_generator():\n",
    "    for seq_name in seq_names:\n",
    "        seq = fasta.fetch(seq_name).upper().replace('-','')[:max_seq_len]\n",
    "        for start_idx in range(0,len(seq),chunk_len-overlap_bp):\n",
    "            chunk = seq[start_idx:start_idx+chunk_len]\n",
    "            if len(chunk)<6:\n",
    "                continue\n",
    "            k_merized_chunk = kmers_stride1(chunk)\n",
    "            tok = transformer_tokenizer.encode_plus(kmers_stride1(chunk),\n",
    "                                            add_special_tokens=True,)\n",
    "            yield seq_name,seq,tok['input_ids']\n",
    "\n",
    "last_seq_name = ''\n",
    "pbar = tqdm(total=len(seq_names))\n",
    "\n",
    "for seq_name,seq,tokenized_seq in seq_generator():\n",
    "    data.append((seq_name,len(seq),len(tokenized_seq)))\n",
    "    if seq_name!=last_seq_name:\n",
    "        last_seq_name = seq_name\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2aa05d9-6749-49c8-ba89-ae11d1899353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_df = pd.DataFrame(data,columns=['seq_name','seq_len','tok_len'])\n",
    "\n",
    "len_df.tok_len.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
