{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb58da27-c136-44c2-bd19-0854512e54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "import scipy.stats\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890b6ff8-30b1-4bbc-b666-dce036d99786",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/lustre/groups/epigenereg01/workspace/projects/vale/mlm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca15d5d-3d43-4cd7-89da-44683291dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_dir = data_dir + 'human_3utr/probs/'\n",
    "\n",
    "models = {'StateSpace':'stspace',\n",
    "          'StateSpace-SA':'stspace-spaw',\n",
    "          'DNABERT': 'dnabert', \n",
    "          'DNABERT-3UTR': 'dnabert-3utr', \n",
    "          'DNABERT-2': 'dnabert2', \n",
    "          'DNABERT2-3UTR': 'dnabert2-3utr', \n",
    "          '13-mer':'K-mer/13_mer',\n",
    "          'NTv2-250M': 'ntrans-v2-250m',\n",
    "          'NTv2-250M-3UTR': 'ntrans-v2-250m-3utr',\n",
    "          'PhyloP-100way': 'PhyloP100' ,\n",
    "          'PhyloP-241way': 'PhyloP241' ,\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c1e08-28f2-42f4-9594-f97eb13a1103",
   "metadata": {},
   "source": [
    "# Get scores from probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49633ecf-10a0-474e-86cb-cefce5e3698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(glob_path):\n",
    "    res = {}\n",
    "    for probas_file in glob(glob_path):\n",
    "        #print(probas_file)\n",
    "        with open(probas_file, 'rb') as f:\n",
    "            fold_res = pickle.load(f)\n",
    "            #fold_res = {seq_name:{'probs':prob,'seq':seq} for seq_name,prob,seq in zip(fold_res['seq_names'],fold_res['probs'],fold_res['seqs'])}\n",
    "            fold_res = {seq_name:prob for seq_name,prob in zip(fold_res['seq_names'],fold_res['probs'])}\n",
    "            res.update(fold_res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49ec4db-361d-4dac-a9b5-a43ac7cb2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSpace loaded, 18134 sequences\n",
      "StateSpace-SA loaded, 18134 sequences\n",
      "DNABERT loaded, 18134 sequences\n",
      "DNABERT-3UTR loaded, 18134 sequences\n",
      "DNABERT2 loaded, 0 sequences\n",
      "DNABERT2-3UTR loaded, 0 sequences\n",
      "13-mer loaded, 18134 sequences\n",
      "NTv2-250M loaded, 18134 sequences\n",
      "NTv2-250M-3UTR loaded, 18134 sequences\n",
      "PhyloP-100way loaded, 18134 sequences\n",
      "PhyloP-241way loaded, 18134 sequences\n"
     ]
    }
   ],
   "source": [
    "all_model_probas = {}\n",
    "\n",
    "for model, model_path in models.items():\n",
    "    all_model_probas[model] = get_model(probs_dir + '/' + model_path + '/predictions*.pickle')\n",
    "    print(f'{model} loaded, {len(all_model_probas[model])} sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be39f7b-ec63-4ca0-8390-9cd95996a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(seq):\n",
    "    '''\n",
    "    Take sequence reverse complement\n",
    "    '''\n",
    "    compl_dict = {'A':'T', 'C':'G', 'G':'C', 'T':'A'}\n",
    "    compl_seq = ''.join([compl_dict.get(x,x) for x in seq])\n",
    "    rev_seq = compl_seq[::-1]\n",
    "    return rev_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8a08ea-c6ca-47b8-8bdb-1315a48d8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'A':0,'C':1,'G':2,'T':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fd43874-3835-40fd-90ff-8bba42c7bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_fasta = data_dir + 'fasta/Homo_sapiens_rna.fa' #3'UTR on hegative strand should  be reverse complemented\n",
    "\n",
    "def read_fasta(fasta):\n",
    "\n",
    "    seqs = defaultdict(str)\n",
    "    \n",
    "    with open(fasta, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                seq_name = line[1:].rstrip()\n",
    "            else:\n",
    "                seqs[seq_name] += line.rstrip().upper()\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "058d6a5a-10b8-4747-a05d-950b3c71295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_utr = read_fasta(human_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a54b846-18b8-4de3-ba3d-78dc16a9b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "utr_variants = pd.read_csv(data_dir+'variants/selected/variants_snp.tsv', sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f28d9a-1e1e-45f7-a242-f365c10701aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "utr_table = pd.read_csv(data_dir + 'UTR_coords/GRCh38_3_prime_UTR_clean-sorted.bed', sep='\\t',\n",
    "                       header = None, names=['seq_start','seq_end','seq_name','strand'], usecols=[1,2,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7332a0f6-21fc-4e56-9729-cbf48e167cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utr_variants['var_id'] = utr_variants.chrom + '_' + utr_variants.pos.astype(str) + '_' + utr_variants.ref + '_' + utr_variants.alt\n",
    "#utr_variants.set_index('var_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55d675bb-e2f4-491f-8b33-33bde5323360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take reverse complement of ref and alt for variants in genes on the negative strand \n",
    "# since model predictions are reverse complemented for these sequences\n",
    "# this is already taken into account for pos_rel (see dataprep)\n",
    "\n",
    "utr_variants.ref = utr_variants.apply(lambda x:reverse_complement(x.ref) if x.strand=='-' else x.ref, axis=1)\n",
    "utr_variants.alt = utr_variants.apply(lambda x:reverse_complement(x.alt) if x.strand=='-' else x.alt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a57781b-ab28-4d5e-97ca-72c60eede8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhyloP-100way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61000/61000 [00:05<00:00, 11714.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhyloP-241way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61000/61000 [00:05<00:00, 11777.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# get PhyloP conservation scores at variant positions\n",
    "\n",
    "for model_name in ('PhyloP-100way','PhyloP-241way',):\n",
    "\n",
    "    print(model_name)\n",
    "\n",
    "    probas = all_model_probas[model_name]\n",
    "    \n",
    "    for var_idx, var in tqdm(utr_variants.iterrows(), total=len(utr_variants)):\n",
    "        if var.seq_name in probas.keys() and var.seq_name in human_utr.keys():\n",
    "            if var.vartype=='SNP':\n",
    "                assert human_utr[var.seq_name][var.pos_rel] == var.ref\n",
    "                utr_variants.at[var_idx,model_name+'-pref'] = probas[var.seq_name][var.pos_rel]\n",
    "            else:\n",
    "                if var.vartype=='INS':\n",
    "                    left, right = var.pos_rel-2, var.pos_rel+2\n",
    "                else:\n",
    "                    if var.strand=='+':\n",
    "                        left, right = var.pos_rel, var.pos_rel+len(var.ref)\n",
    "                    else:\n",
    "                        left, right = var.pos_rel-len(var.ref), var.pos_rel\n",
    "                    assert human_utr[var.seq_name][left:right] == var.ref\n",
    "                utr_variants.at[var_idx,model_name+'-pref'] = np.mean(probas[var.seq_name][left:right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e04a844c-f587-4aa5-9529-e8527c6891a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model_res(model_name):\n",
    "\n",
    "    print(model_name)\n",
    "\n",
    "    probas = all_model_probas[model_name]\n",
    "        \n",
    "    for var_idx, var in tqdm(utr_variants.iterrows(), total=len(utr_variants)):\n",
    "        if var.seq_name in probas.keys() and var.seq_name in human_utr.keys():\n",
    "            if var.vartype=='SNP':\n",
    "                assert human_utr[var.seq_name][var.pos_rel] == var.ref\n",
    "                utr_variants.at[var_idx, model_name+'-palt'] = probas[var.seq_name][var.pos_rel, mapping[var.alt]]\n",
    "                utr_variants.at[var_idx, model_name+'-pref'] = probas[var.seq_name][var.pos_rel, mapping[var.ref]]\n",
    "            else:\n",
    "                if var.vartype=='INS':\n",
    "                    left, right = var.pos_rel-2, var.pos_rel+2\n",
    "                else:\n",
    "                    if var.strand=='+':\n",
    "                        left, right = var.pos_rel, var.pos_rel+len(var.ref)\n",
    "                    else:\n",
    "                        left, right = var.pos_rel-len(var.ref), var.pos_rel\n",
    "                ref_score = []\n",
    "                seq = human_utr[var.seq_name]\n",
    "                assert seq[left:right] == var.ref\n",
    "                for pos_rel in range(max(left,0),min(right,len(seq))):\n",
    "                    ref_score.append(probas[var.seq_name][pos_rel, mapping[seq[pos_rel]]]) \n",
    "                    #ref_score.append(np.max(probas[var.seq_name][pos_rel])) \n",
    "                utr_variants.at[var_idx, model_name+'-pref'] = np.mean(ref_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71eff750-bf92-48a6-babe-53054a9fd019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSpace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61000/61000 [00:07<00:00, 8448.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSpace-SA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61000/61000 [00:07<00:00, 8372.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNABERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61000/61000 [00:07<00:00, 8190.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNABERT-3UTR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61000/61000 [00:07<00:00, 8024.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-mer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61000/61000 [00:07<00:00, 8066.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTv2-250M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61000/61000 [00:07<00:00, 8004.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTv2-250M-3UTR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61000/61000 [00:07<00:00, 8075.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_name in ('StateSpace', 'StateSpace-SA',\n",
    "          'DNABERT', 'DNABERT-3UTR', '13-mer','NTv2-250M','NTv2-250M-3UTR'):\n",
    "    add_model_res(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cedce-2182-47a7-b532-3634d1ea9836",
   "metadata": {},
   "source": [
    "# Get scores from embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7cfdca6-09cf-4ae7-b230-95e0fe04b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings_score(seq_names,embeddings,losses,model_name):\n",
    "    res = []\n",
    "    #loss_ref_avg, loss_ref_central, loss_alt_avg, loss_alt_central = None, None, None, None #we don't compute score base on losses here\n",
    "    for idx in range(0,len(embeddings),2):\n",
    "        assert seq_names[idx]==seq_names[idx+1].replace('alt','ref')\n",
    "        emb_ref, emb_alt = embeddings[idx], embeddings[idx+1]\n",
    "        l2 = np.linalg.norm(emb_ref-emb_alt)\n",
    "        l1 = np.linalg.norm((emb_ref-emb_alt), ord=1)\n",
    "        dot = np.dot(emb_ref,emb_alt)\n",
    "        cosine = dot/(np.linalg.norm(emb_ref)*np.linalg.norm(emb_alt))\n",
    "        loss_ref, loss_alt = losses[idx], losses[idx+1]\n",
    "        varname = seq_names[idx].replace('_ref','').split('_')\n",
    "        res.append((varname[0],int(varname[1]),varname[2],varname[3],l1,l2,dot,cosine,loss_ref,loss_alt))\n",
    "    res = pd.DataFrame(res,columns=['chrom','pos','ref','alt',\n",
    "        f'{model_name}-l1',f'{model_name}-l2',f'{model_name}-dot',f'{model_name}-cosine',\n",
    "        f'{model_name}-loss_ref', f'{model_name}-loss_alt'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e4c2ebe-4ea9-4d18-88ba-5904e4a3ba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSpace\n",
      "StateSpace-SA\n",
      "DNABERT2\n",
      "DNABERT2-3UTR\n",
      "DNABERT\n",
      "DNABERT-3UTR\n",
      "NTv2-250M\n",
      "NTv2-250M-3UTR\n"
     ]
    }
   ],
   "source": [
    "emb_dir  = data_dir + 'variants/embeddings/'\n",
    "\n",
    "for model_name in ('StateSpace', 'StateSpace-SA', 'DNABERT-2', 'DNABERT2-3UTR',\n",
    "          'DNABERT', 'DNABERT-3UTR', 'NTv2-250M','NTv2-250M-3UTR'):\n",
    "    \n",
    "    print(model_name)\n",
    "    \n",
    "    with open(emb_dir + models[model_name] + '/predictions.pickle', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    embeddings_scores = compute_embeddings_score(data['seq_names'],data['embeddings'], data['losses'],model_name)\n",
    "    \n",
    "    utr_variants = utr_variants.merge(embeddings_scores, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbb298-03d5-4a46-b729-094f66c635e7",
   "metadata": {},
   "source": [
    "# Get scores from supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93196f12-8e45-4caf-9b65-9c834be674b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier in ('LogisticRegression','MLP'):\n",
    "    \n",
    "    pred_dir  = data_dir + f'variants/predictions/merge_embeddings_1/{classifier}/'\n",
    "    \n",
    "    for model_name in ('StateSpace', 'StateSpace-SA', 'DNABERT-2', 'DNABERT2-3UTR',\n",
    "          'DNABERT', 'DNABERT-3UTR', 'NTv2-250M','NTv2-250M-3UTR'):\n",
    "\n",
    "        model_res = []\n",
    "\n",
    "        for subset in ('clinvar','gnomAD','eQTL-susie','eQTL-GRASP'):\n",
    "\n",
    "            pred_res = pred_dir + subset  + '-' + models[model_name] + '.tsv'\n",
    "            \n",
    "            if os.path.isfile(pred_res):\n",
    "                subset_df = pd.read_csv(pred_res,sep='\\t')\n",
    "                model_res.append(subset_df)\n",
    "            else:\n",
    "                print(pred_res)\n",
    "\n",
    "        if len(model_res)>0:\n",
    "            model_res = pd.concat(model_res)\n",
    "            model_res.rename(columns={'y_pred':model_name+'-'+classifier},inplace=True)\n",
    "            utr_variants = utr_variants.merge(model_res,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03d843b3-a711-4651-b05c-5cd66ee5e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "utr_variants.to_csv(data_dir + 'variants/model_scores_snp.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f399fa-1943-4f42-9a65-8d7b6c6b089d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
