{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb58da27-c136-44c2-bd19-0854512e54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import sklearn, sklearn.linear_model, sklearn.metrics, sklearn.pipeline,sklearn.ensemble\n",
    "\n",
    "import matplotlib\n",
    "import scipy.stats\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890b6ff8-30b1-4bbc-b666-dce036d99786",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/lustre/groups/epigenereg01/workspace/projects/vale/MLM/motif_predictions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca15d5d-3d43-4cd7-89da-44683291dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { 'Species-agnostic':'species_agnostic/probas.pickle','Species-aware':'species_aware/probas.pickle', \n",
    "          'DNABERT': 'dnabert/default/*.pickle', '11-mer':'K-mer/11_mer.pickle','13-mer':'K-mer/13_mer.pickle',\n",
    "          'PhyloP-100way': '../PhyloP/PhyloP100_3UTR.pickle' ,'PhyloP-241way': '../PhyloP/PhyloP241_3UTR.pickle', 'NT-MS-v2-500M': 'split_75_25/ntrans/NT-MS-v2-500M/*.pickle'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c1e08-28f2-42f4-9594-f97eb13a1103",
   "metadata": {},
   "source": [
    "# Get scores from probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49633ecf-10a0-474e-86cb-cefce5e3698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(glob_path):\n",
    "    res = {}\n",
    "    for probas_file in glob(glob_path):\n",
    "        #print(probas_file)\n",
    "        with open(probas_file, 'rb') as f:\n",
    "            model_probas = pickle.load(f)\n",
    "            if len(model_probas)==2:\n",
    "                res.update({model_probas[0]:model_probas[1]})\n",
    "            else:\n",
    "                res.update(dict(model_probas))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa843070-a89d-4ce3-8089-998469d2e833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species-agnostic loaded, 18134 sequences\n",
      "Species-aware loaded, 18134 sequences\n",
      "DNABERT loaded, 18134 sequences\n",
      "11-mer loaded, 18134 sequences\n",
      "13-mer loaded, 18134 sequences\n",
      "PhyloP-100way loaded, 18178 sequences\n",
      "PhyloP-241way loaded, 18178 sequences\n",
      "NT-MS-v2-500M loaded, 4245 sequences\n"
     ]
    }
   ],
   "source": [
    "all_model_probas = {}\n",
    "\n",
    "for model_name in models:\n",
    "    all_model_probas[model_name] = get_model(data_dir + models[model_name])\n",
    "    print(f'{model_name} loaded, {len(all_model_probas[model_name])} sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be39f7b-ec63-4ca0-8390-9cd95996a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(seq):\n",
    "    '''\n",
    "    Take sequence reverse complement\n",
    "    '''\n",
    "    compl_dict = {'A':'T', 'C':'G', 'G':'C', 'T':'A'}\n",
    "    compl_seq = ''.join([compl_dict.get(x,x) for x in seq])\n",
    "    rev_seq = compl_seq[::-1]\n",
    "    return rev_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8a08ea-c6ca-47b8-8bdb-1315a48d8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'A':0,'C':1,'G':2,'T':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fd43874-3835-40fd-90ff-8bba42c7bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_fasta = data_dir + '../fasta/240_species/species/Homo_sapiens.fa' #3'UTR on hegative strand should  be reverse complemented\n",
    "\n",
    "human_utr = defaultdict(str)\n",
    "\n",
    "with open(human_fasta, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('>'):\n",
    "            seq_name = line[1:].split(':')[0]\n",
    "        else:\n",
    "            human_utr[seq_name] += line.rstrip().upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a54b846-18b8-4de3-ba3d-78dc16a9b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "utr_variants = pd.read_csv(data_dir+'../perbase_pred/variants_snp.tsv', sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d675bb-e2f4-491f-8b33-33bde5323360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take reverse complement of ref and alt for variants in genes on the negative strand \n",
    "# since model predictions are reverse complemented for these sequences\n",
    "# this is already taken into account for pos_rel (see dataprep)\n",
    "\n",
    "utr_variants.ref = utr_variants.apply(lambda x:reverse_complement(x.ref) if x.strand=='-' else x.ref, axis=1)\n",
    "utr_variants.alt = utr_variants.apply(lambda x:reverse_complement(x.alt) if x.strand=='-' else x.alt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a57781b-ab28-4d5e-97ca-72c60eede8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhyloP-100way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42411/42411 [00:06<00:00, 6895.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhyloP-241way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42411/42411 [00:05<00:00, 7937.80it/s] \n"
     ]
    }
   ],
   "source": [
    "# get PhyloP conservation scores at variant positions\n",
    "\n",
    "for model_name in ('PhyloP-100way','PhyloP-241way',):\n",
    "\n",
    "    print(model_name)\n",
    "\n",
    "    probas = all_model_probas[model_name]\n",
    "    \n",
    "    for var_idx, var in tqdm(utr_variants.iterrows(), total=len(utr_variants)):\n",
    "        if var.seq_name in probas.keys() and var.seq_name in human_utr.keys():\n",
    "            if var.vartype=='SNP':\n",
    "                assert human_utr[var.seq_name][var.pos_rel] == var.ref\n",
    "                utr_variants.at[var_idx,model_name+'_ref'] = probas[var.seq_name][var.pos_rel]\n",
    "            else:\n",
    "                if var.vartype=='INS':\n",
    "                    left, right = var.pos_rel-2, var.pos_rel+2\n",
    "                else:\n",
    "                    if var.strand=='+':\n",
    "                        left, right = var.pos_rel, var.pos_rel+len(var.ref)\n",
    "                    else:\n",
    "                        left, right = var.pos_rel-len(var.ref), var.pos_rel\n",
    "                    assert human_utr[var.seq_name][left:right] == var.ref\n",
    "                utr_variants.at[var_idx,model_name+'_ref'] = np.mean(probas[var.seq_name][left:right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04a844c-f587-4aa5-9529-e8527c6891a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model_res(model_name):\n",
    "\n",
    "    print(model_name)\n",
    "\n",
    "    probas = all_model_probas[model_name]\n",
    "        \n",
    "    for var_idx, var in tqdm(utr_variants.iterrows(), total=len(utr_variants)):\n",
    "        if var.seq_name in probas.keys() and var.seq_name in human_utr.keys():\n",
    "            if var.vartype=='SNP':\n",
    "                assert human_utr[var.seq_name][var.pos_rel] == var.ref\n",
    "                utr_variants.at[var_idx, model_name+'_alt'] = probas[var.seq_name][var.pos_rel, mapping[var.alt]]\n",
    "                utr_variants.at[var_idx, model_name+'_ref'] = probas[var.seq_name][var.pos_rel, mapping[var.ref]]\n",
    "            else:\n",
    "                if var.vartype=='INS':\n",
    "                    left, right = var.pos_rel-2, var.pos_rel+2\n",
    "                else:\n",
    "                    if var.strand=='+':\n",
    "                        left, right = var.pos_rel, var.pos_rel+len(var.ref)\n",
    "                    else:\n",
    "                        left, right = var.pos_rel-len(var.ref), var.pos_rel\n",
    "                ref_score = []\n",
    "                seq = human_utr[var.seq_name]\n",
    "                assert seq[left:right] == var.ref\n",
    "                for pos_rel in range(max(left,0),min(right,len(seq))):\n",
    "                    ref_score.append(probas[var.seq_name][pos_rel, mapping[seq[pos_rel]]]) \n",
    "                    #ref_score.append(np.max(probas[var.seq_name][pos_rel])) \n",
    "                utr_variants.at[var_idx, model_name+'_ref'] = np.mean(ref_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71eff750-bf92-48a6-babe-53054a9fd019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species-aware\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42411/42411 [00:07<00:00, 5808.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species-agnostic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42411/42411 [00:07<00:00, 5386.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNABERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42411/42411 [00:07<00:00, 5420.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-mer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42411/42411 [00:07<00:00, 5340.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-mer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42411/42411 [00:07<00:00, 5455.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT-MS-v2-500M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42411/42411 [00:03<00:00, 12388.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_name in ('Species-aware', 'Species-agnostic', 'DNABERT', '11-mer','13-mer', 'NT-MS-v2-500M'):\n",
    "    add_model_res(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cedce-2182-47a7-b532-3634d1ea9836",
   "metadata": {},
   "source": [
    "# Get scores from embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "77f730e7-c418-4f70-ba26-dc9dd89521ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dir =  data_dir + '../perbase_pred/embeddings_scores/'\n",
    "\n",
    "def concat_embeddings(model_name):\n",
    "    '''\n",
    "    collect embeddings from all batches and save in a single file\n",
    "    '''\n",
    "    print(f'loadding embeddings for {model_name}')\n",
    "    res = []\n",
    "    for emb_file in tqdm(glob(embeddings_dir + f'{model_name}/chr*.pickle')):\n",
    "        with open(emb_file, 'rb') as f:\n",
    "            seq_names, embeddings, logprobas = pickle.load(f)\n",
    "            if len(logprobas)==0:\n",
    "                logprobas = [[] for _ in range(len(seq_names))]            \n",
    "            res.extend(zip(seq_names,embeddings,logprobas))\n",
    "    with open(embeddings_dir + f'{model_name}/embeddings.pickle', 'wb') as f:\n",
    "        print(f'putting all embeddings into a single file')\n",
    "        pickle.dump(res,f)\n",
    "        print(f'deleting batch files')\n",
    "        #for f in glob(embeddings_dir + f'{model_name}/chr*.pickle'):\n",
    "        #    os.remove(f)\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7ece4ada-9b5a-43d4-a233-f424e517617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings_score(seq_names,embeddings,losses,model_name):\n",
    "    res = []\n",
    "    loss_ref_avg, loss_ref_central, loss_alt_avg, loss_alt_central = None, None, None, None #we don't compute score base on losses here\n",
    "    for idx in range(0,len(embeddings),2):\n",
    "        assert seq_names[idx]==seq_names[idx+1].replace('alt','ref')\n",
    "        emb_ref, emb_alt = embeddings[idx], embeddings[idx+1]\n",
    "        l2 = np.linalg.norm(emb_ref-emb_alt)\n",
    "        l1 = np.linalg.norm((emb_ref-emb_alt), ord=1)\n",
    "        dot = np.dot(emb_ref,emb_alt)\n",
    "        cosine = dot/(np.linalg.norm(emb_ref)*np.linalg.norm(emb_alt))\n",
    "        #loss_ref, loss_alt = losses[idx], losses[idx+1]\n",
    "        #if len(loss_ref)>0:\n",
    "        #    loss_ref_avg, loss_ref_central = np.mean(loss_ref), loss_ref[len(loss_ref)//2]\n",
    "        #    loss_alt_avg, loss_alt_central = np.mean(loss_alt), loss_alt[len(loss_alt)//2]\n",
    "        #else:\n",
    "        #    loss_ref_avg, loss_ref_central, loss_alt_avg, loss_alt_central = None, None, None, None\n",
    "        varname = seq_names[idx].replace('_ref','').split('_')\n",
    "        res.append((varname[0],int(varname[1]),varname[2],varname[3],l1,l2,dot,cosine,loss_ref_avg, loss_ref_central,loss_alt_avg, loss_alt_central))\n",
    "        #print(f'{varname[0]}\\t{varname[1]}\\t{varname[2]}\\t{varname[3]}\\t{l1}\\t{l2}\\t{dot}\\t{cosine}\\t{loss_ref_avg}\\t{loss_ref_central}\\t{loss_alt_avg}\\t{loss_alt_central}')\n",
    "    res = pd.DataFrame(res,columns=['chrom','pos','ref','alt',\n",
    "        f'{model_name}-l1',f'{model_name}-l2',f'{model_name}-dot',f'{model_name}-cosine',\n",
    "        f'{model_name}-loss_ref_avg',f'{model_name}-loss_ref_cent', f'{model_name}-loss_alt_avg',f'{model_name}-loss_alt_cent'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e0f2dc77-5895-45cd-9553-3f960ebfa3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadding embeddings for DNABERT-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2828/2828 [01:20<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "putting all embeddings into a single file\n",
      "deleting batch files\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "concat_embeddings('DNABERT-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d725464-05cc-45ae-93bb-a4e0bd93c816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'DNABERT-2'\n",
    "\n",
    "emb_file = embeddings_dir + f'{model_name}/embeddings.pickle'\n",
    "with open(emb_file, 'rb') as f:\n",
    "    seq_names,embeddings,losses = zip(*pickle.load(f))\n",
    "\n",
    "compute_embeddings_score(seq_names,embeddings,losses,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d843b3-a711-4651-b05c-5cd66ee5e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "utr_variants.to_csv(data_dir + '../perbase_pred/model_scores_snp.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd56d9e-754c-4f9f-9fad-2db16bea4e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
